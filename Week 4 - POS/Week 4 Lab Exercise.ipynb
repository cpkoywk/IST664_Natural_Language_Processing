{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pan Chen**\n",
    "**Week 4 Lab**\n",
    "\n",
    "\n",
    "## Lab Exercise\n",
    "\n",
    "- Run the regexp tokenizer with the regular pattern on the sentence “Mr. Black and Mrs. Brown attended the lecture by Dr. Gray, but Gov. White wasn’t there.”\n",
    "\n",
    "a. Design and add a line to the pattern of this tokenizer so that titles like “Mr.” \n",
    "are tokenized as having the dot inside the token. Test and add some other titles to your list of titles.\n",
    "\n",
    "b. Design and add the pattern of this tokenizer so that words with a single apostrophe, such as “wasn’t” are taken as a single token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr. ', 'Black ', 'and ', 'Mrs. ', 'Brown ', 'attended ', 'the ', 'lecture ', 'by ', 'Dr. ', 'Gray, ', 'but ', 'Gov. ', 'White ', 'wasn', '’', 't', 'there', '.'] \n",
      "\n",
      "['Mr. ', 'Black ', 'and ', 'Mrs. ', 'Brown ', 'attended ', 'the ', 'lecture ', 'by ', 'Dr. ', 'Gray, ', 'but ', 'Gov. ', 'White ', 'wasn’t', 'there', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Run the regexp tokenizer with the regular pattern on \n",
    "#the sentence “Mr. Black and Mrs. Brown attended the lecture by Dr. Gray, but Gov. White wasn’t there.”\n",
    "\n",
    "#import the package\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "tmp = \"Mr. Black and Mrs. Brown attended the lecture by Dr. Gray, but Gov. White wasn’t there.\"\n",
    "\n",
    "'''1. Design and add a line to the pattern of this tokenizer so that titles like “Mr.” \n",
    "are tokenized as having the dot inside the token. Test and add some other titles to your list of titles.\n",
    "'''\n",
    "pattern = r''' (?x) \t# set flag to allow verbose regexps\n",
    "         \\w+.\\ #to allow dot\n",
    "        | (?:[A-Z]\\.)+    # abbreviations, e.g. U.S.A.\n",
    "        | \\$?\\d+(?:\\.\\d+)?%?    # currency and percentages, $12.40, 50%\n",
    "        | \\w+(?:-\\w+)*  # words with internal hyphens\n",
    "        | \\.\\.\\.        # ellipsis\n",
    "        | [][.,;”’?():-_%#’]    # separate tokens\n",
    "        '''\n",
    "print(nltk.regexp_tokenize(tmp, pattern),\"\\n\")\n",
    "\n",
    "'''b. Design and add the pattern of this tokenizer so that words with a single\n",
    "apostrophe, such as “wasn't” are taken as a single token.\n",
    "'''\n",
    "\n",
    "pattern2 = r''' (?x) \t# set flag to allow verbose regexps\n",
    "        (?:[A-Z]\\.)+    # abbreviations, e.g. U.S.A.\n",
    "        | \\$?\\d+(?:\\.\\d+)?%?    # currency and percentages, $12.40, 50%\n",
    "        | \\w+.\\ #to allow dot\n",
    "        | \\w+(?:’\\w+)*  # words with internal apostrophe\n",
    "        | \\w+(?:-\\w+)*  # words with internal hyphens\n",
    "        | \\.\\.\\.        # ellipsis\n",
    "        | [][.,;”’?():-_%#’]    # separate tokens\n",
    "\n",
    "        '''\n",
    "                              \n",
    "print(nltk.regexp_tokenize(tmp, pattern2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

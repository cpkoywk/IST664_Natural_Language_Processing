{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of basic notations to match single characters\n",
    "and sequences of characters**\n",
    "\n",
    "1. /[abc]/ = /a|b|c/ Character class; disjunction\n",
    "matches one of a, b or c\n",
    "\n",
    "2. /[b-e]/ = /b|c|d|e/ Range in a character class\n",
    "\n",
    "3. /[^b-e]/ Complement of character class\n",
    "4. /./ Wildcard matches any character\n",
    "5. /a*/ /[af]*/ /(abc)*/ Kleene star: zero or more\n",
    "6. /a?/ /(ab|ca)?/ Zero or one; optional\n",
    "7. /a+/ /([a-zA-Z]1|ca)+/ Kleene plus: one or more\n",
    "8. /a{8}/ /b{1,2}/ /c{3,}/ Counters: exact number of repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "/^a/ pattern must match at beginning of string\n",
    "/a$/ pattern musch math the end of string\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Text from Files, Stemming and Lemmatization Lab Exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import all the necessary packages\n",
    "import nltk\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1176965\n",
      "ï»¿The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, giv\n"
     ]
    }
   ],
   "source": [
    "#text from guteberg.org\n",
    "#this the url of the book \"Crime and Punishment\"\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response =request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\\r\\n<html>\\r\\n<head>\\r\\n<title>BBC NEWS | Health | Blondes \\'to die out in 200 years\\'</title>\\r\\n<meta name=\"keywords\" content=\"BBC, News, BBC News, news online, world, uk, international, foreign, british, online, service\">\\r\\n<meta name=\"OriginalPublicationDate\" content=\"2002/09/27 11:51:55\">\\r\\n<meta name=\"UKFS_URL\" content=\"/1/hi/health/2284783.stm\">\\r\\n<meta name=\"IFS_URL\" content=\"/2/hi/health/2284783.stm\">\\r\\n<meta name=\"HTTP-EQUIV\" content=\"text/html;charset=iso-8859-1\">\\r\\n<meta name=\"Headline\" content=\"Blondes \\'to die out in 200 years\\'\">\\r\\n<meta name=\"Section\" content=\"Health\">\\r\\n<meta name=\"Description\" content=\"Natural blondes are an endangered species and will die out by 2202, a study suggests.\">\\r\\n<!-- GENMaps-->\\r\\n<map name=\"banner\">\\r\\n<area alt=\"BBC NEWS\" coords=\"7,9,167,32\" href=\"http://news.bbc.co.uk/1/hi.html\" shape=\"RECT\">\\r\\n</map>\\r\\n\\r\\n<script src=\"/nol/shared/js/livestats_v1_1.js\" langua'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optional\n",
    "#Let's try to import another text with html formatting\n",
    "blondurl=\"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(blondurl).read().decode('utf8')\n",
    "html[:1000]\n",
    "#As we can see this text file contains a lot of shit\n",
    "#import bs4 to remove html markups\n",
    "from bs4 import BeautifulSoup\n",
    "#Get the contents as a BeautifulSoup object:\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "#Use the get_text function to get the contents of all the text tags.\n",
    "braw = soup.get_text()\n",
    "btokens = nltk.word_tokenize(braw)\n",
    "btokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 2 of 2 matches:\n",
      " Shaiba range of mountainous dunes , pass by the quicksand of Umm al Samim ( M\n",
      " Shaiba range of mountainous dunes , pass by the quicksand of Umm al Samim ( M\n"
     ]
    }
   ],
   "source": [
    "#read the txt file\n",
    "fin = open('desert.txt')\n",
    "rawtext = fin.read()\n",
    "\n",
    "\n",
    "deserttokens = nltk.word_tokenize(rawtext)\n",
    "text = nltk.Text(deserttokens)\n",
    "text.concordance('pass')\n",
    "\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Produced',\n",
       " 'by',\n",
       " 'John',\n",
       " 'Bickers',\n",
       " ';',\n",
       " 'and',\n",
       " 'Dagny',\n",
       " 'CRIME',\n",
       " 'AND',\n",
       " 'PUNISHMENT',\n",
       " 'By',\n",
       " 'Fyodor',\n",
       " 'Dostoevsky',\n",
       " 'Translated',\n",
       " 'By',\n",
       " 'Constance',\n",
       " 'Garnett',\n",
       " 'TRANSLATOR',\n",
       " \"'S\",\n",
       " 'PREFACE',\n",
       " 'A',\n",
       " 'few',\n",
       " 'words',\n",
       " 'about',\n",
       " 'Dostoevsky',\n",
       " 'himself',\n",
       " 'may',\n",
       " 'help',\n",
       " 'the',\n",
       " 'English',\n",
       " 'reader',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'his',\n",
       " 'work',\n",
       " '.',\n",
       " 'Dostoevsky',\n",
       " 'was',\n",
       " 'the',\n",
       " 'son',\n",
       " 'of',\n",
       " 'a',\n",
       " 'doctor',\n",
       " '.',\n",
       " 'His',\n",
       " 'parents',\n",
       " 'were',\n",
       " 'very',\n",
       " 'hard-working',\n",
       " 'and',\n",
       " 'deeply',\n",
       " 'religious',\n",
       " 'people',\n",
       " ',',\n",
       " 'but',\n",
       " 'so',\n",
       " 'poor',\n",
       " 'that',\n",
       " 'they',\n",
       " 'lived',\n",
       " 'with',\n",
       " 'their',\n",
       " 'five',\n",
       " 'children',\n",
       " 'in',\n",
       " 'only',\n",
       " 'two',\n",
       " 'rooms',\n",
       " '.',\n",
       " 'The',\n",
       " 'father',\n",
       " 'and',\n",
       " 'mother',\n",
       " 'spent',\n",
       " 'their',\n",
       " 'evenings',\n",
       " 'in',\n",
       " 'reading',\n",
       " 'aloud',\n",
       " 'to',\n",
       " 'their',\n",
       " 'children',\n",
       " ',',\n",
       " 'generally',\n",
       " 'from',\n",
       " 'books',\n",
       " 'of',\n",
       " 'a',\n",
       " 'serious',\n",
       " 'character',\n",
       " '.',\n",
       " 'Though',\n",
       " 'always',\n",
       " 'sickly',\n",
       " 'and',\n",
       " 'delicate',\n",
       " 'Dostoevsky',\n",
       " 'came',\n",
       " 'out',\n",
       " 'third']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming and lemmatization\n",
    "f = open('CrimeAndPunishment.txt')\n",
    "crimetext = f.read()\n",
    "\n",
    "#Tokenize the text and make crimewords to have lower-case words with no capitalization.\n",
    "crimetokens = nltk.word_tokenize(crimetext)\n",
    "print(len(crimetokens))\n",
    "print(crimetokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['produc', 'by', 'john', 'bicker', ';', 'and', 'dagni', 'crime', 'and', 'punish', 'By', 'fyodor', 'dostoevski', 'translat', 'By', 'constanc', 'garnett', 'translat', \"'S\", 'prefac', 'A', 'few', 'word', 'about', 'dostoevski', 'himself', 'may', 'help', 'the', 'english', 'reader', 'to', 'understand', 'hi', 'work', '.', 'dostoevski', 'wa', 'the', 'son', 'of', 'a', 'doctor', '.', 'hi', 'parent', 'were', 'veri', 'hard-work', 'and', 'deepli', 'religi', 'peopl', ',', 'but', 'so', 'poor', 'that', 'they', 'live', 'with', 'their', 'five', 'children', 'in', 'onli', 'two', 'room', '.', 'the', 'father', 'and', 'mother', 'spent', 'their', 'even', 'in', 'read', 'aloud', 'to', 'their', 'children', ',', 'gener', 'from', 'book', 'of', 'a', 'seriou', 'charact', '.', 'though', 'alway', 'sickli', 'and', 'delic', 'dostoevski', 'came', 'out', 'third', 'in', 'the', 'final', 'examin', 'of', 'the', 'petersburg', 'school', 'of', 'engin', '.', 'there', 'he', 'had', 'alreadi', 'begun', 'hi', 'first', 'work', ',', '``', 'poor', 'folk', '.', \"''\", 'thi', 'stori', 'wa', 'publish', 'by', 'the', 'poet', 'nekrassov', 'in', 'hi', 'review', 'and', 'wa', 'receiv', 'with', 'acclam', '.', 'the', 'shi', ',', 'unknown', 'youth', 'found', 'himself', 'instantli', 'someth', 'of', 'a', 'celebr', '.', 'A', 'brilliant', 'and', 'success', 'career', 'seem', 'to', 'open', 'befor', 'him', ',', 'but', 'those', 'hope', 'were', 'soon', 'dash', '.', 'In', '1849', 'he', 'wa', 'arrest', '.', 'though', 'neither', 'by', 'tempera', 'nor', 'convict', 'a', 'revolutionist', ',', 'dostoevski', 'wa', 'one', 'of', 'a', 'littl', 'group', 'of', 'young', 'men', 'who', 'met'] \n",
      "\n",
      "['produc', 'by', 'john', 'bick', ';', 'and', 'dagny', 'crim', 'and', 'pun', 'by', 'fyod', 'dostoevsky', 'transl', 'by', 'const', 'garnet', 'transl', \"'s\", 'prefac', 'a', 'few', 'word', 'about', 'dostoevsky', 'himself', 'may', 'help', 'the', 'engl', 'read', 'to', 'understand', 'his', 'work', '.', 'dostoevsky', 'was', 'the', 'son', 'of', 'a', 'doct', '.', 'his', 'par', 'wer', 'very', 'hard-working', 'and', 'deeply', 'religy', 'peopl', ',', 'but', 'so', 'poor', 'that', 'they', 'liv', 'with', 'their', 'fiv', 'childr', 'in', 'on', 'two', 'room', '.', 'the', 'fath', 'and', 'moth', 'spent', 'their', 'ev', 'in', 'read', 'aloud', 'to', 'their', 'childr', ',', 'gen', 'from', 'book', 'of', 'a', 'sery', 'charact', '.', 'though', 'alway', 'sick', 'and', 'del', 'dostoevsky', 'cam', 'out', 'third', 'in', 'the', 'fin', 'examin', 'of', 'the', 'petersburg', 'school', 'of', 'engin', '.', 'ther', 'he', 'had', 'already', 'begun', 'his', 'first', 'work', ',', '``', 'poor', 'folk', '.', \"''\", 'thi', 'story', 'was', 'publ', 'by', 'the', 'poet', 'nekrassov', 'in', 'his', 'review', 'and', 'was', 'receiv', 'with', 'acclam', '.', 'the', 'shy', ',', 'unknown', 'you', 'found', 'himself', 'inst', 'someth', 'of', 'a', 'celebr', '.', 'a', 'bril', 'and', 'success', 'car', 'seem', 'to', 'op', 'bef', 'him', ',', 'but', 'thos', 'hop', 'wer', 'soon', 'dash', '.', 'in', '1849', 'he', 'was', 'arrest', '.', 'though', 'neith', 'by', 'tempera', 'nor', 'convict', 'a', 'revolv', ',', 'dostoevsky', 'was', 'on', 'of', 'a', 'littl', 'group', 'of', 'young', 'men', 'who', 'met']\n"
     ]
    }
   ],
   "source": [
    "#NLTK has two stemmers, you first create them\n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "#compare how the 2 stemmers work on a small portion of the tokens\n",
    "crimePstem = [porter.stem(t) for t in crimetokens]\n",
    "print(crimePstem[:200],'\\n')\n",
    "crimeLstem = [lancaster.stem(t) for t in crimetokens] \n",
    "print(crimeLstem[:200])\n",
    "\n",
    "#The Lancaster stemmer has lower-cased all the words, and in some cases, it appears to\n",
    "#be a little more severe in removing word endings, but in others not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Produced',\n",
       " 'by',\n",
       " 'John',\n",
       " 'Bickers',\n",
       " ';',\n",
       " 'and',\n",
       " 'Dagny',\n",
       " 'CRIME',\n",
       " 'AND',\n",
       " 'PUNISHMENT',\n",
       " 'By',\n",
       " 'Fyodor',\n",
       " 'Dostoevsky',\n",
       " 'Translated',\n",
       " 'By',\n",
       " 'Constance',\n",
       " 'Garnett',\n",
       " 'TRANSLATOR',\n",
       " \"'S\",\n",
       " 'PREFACE',\n",
       " 'A',\n",
       " 'few',\n",
       " 'word',\n",
       " 'about',\n",
       " 'Dostoevsky',\n",
       " 'himself',\n",
       " 'may',\n",
       " 'help',\n",
       " 'the',\n",
       " 'English',\n",
       " 'reader',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'his',\n",
       " 'work',\n",
       " '.',\n",
       " 'Dostoevsky',\n",
       " 'wa',\n",
       " 'the',\n",
       " 'son',\n",
       " 'of',\n",
       " 'a',\n",
       " 'doctor',\n",
       " '.',\n",
       " 'His',\n",
       " 'parent',\n",
       " 'were',\n",
       " 'very',\n",
       " 'hard-working',\n",
       " 'and',\n",
       " 'deeply',\n",
       " 'religious',\n",
       " 'people',\n",
       " ',',\n",
       " 'but',\n",
       " 'so',\n",
       " 'poor',\n",
       " 'that',\n",
       " 'they',\n",
       " 'lived',\n",
       " 'with',\n",
       " 'their',\n",
       " 'five',\n",
       " 'child',\n",
       " 'in',\n",
       " 'only',\n",
       " 'two',\n",
       " 'room',\n",
       " '.',\n",
       " 'The',\n",
       " 'father',\n",
       " 'and',\n",
       " 'mother',\n",
       " 'spent',\n",
       " 'their',\n",
       " 'evening',\n",
       " 'in',\n",
       " 'reading',\n",
       " 'aloud',\n",
       " 'to',\n",
       " 'their',\n",
       " 'child',\n",
       " ',',\n",
       " 'generally',\n",
       " 'from',\n",
       " 'book',\n",
       " 'of',\n",
       " 'a',\n",
       " 'serious',\n",
       " 'character',\n",
       " '.',\n",
       " 'Though',\n",
       " 'always',\n",
       " 'sickly',\n",
       " 'and',\n",
       " 'delicate',\n",
       " 'Dostoevsky',\n",
       " 'came',\n",
       " 'out',\n",
       " 'third',\n",
       " 'in',\n",
       " 'the',\n",
       " 'final',\n",
       " 'examination',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Petersburg',\n",
       " 'school',\n",
       " 'of',\n",
       " 'Engineering',\n",
       " '.',\n",
       " 'There',\n",
       " 'he',\n",
       " 'had',\n",
       " 'already',\n",
       " 'begun',\n",
       " 'his',\n",
       " 'first',\n",
       " 'work',\n",
       " ',',\n",
       " '``',\n",
       " 'Poor',\n",
       " 'Folk',\n",
       " '.',\n",
       " \"''\",\n",
       " 'This',\n",
       " 'story',\n",
       " 'wa',\n",
       " 'published',\n",
       " 'by',\n",
       " 'the',\n",
       " 'poet',\n",
       " 'Nekrassov',\n",
       " 'in',\n",
       " 'his',\n",
       " 'review',\n",
       " 'and',\n",
       " 'wa',\n",
       " 'received',\n",
       " 'with',\n",
       " 'acclamation',\n",
       " '.',\n",
       " 'The',\n",
       " 'shy',\n",
       " ',',\n",
       " 'unknown',\n",
       " 'youth',\n",
       " 'found',\n",
       " 'himself',\n",
       " 'instantly',\n",
       " 'something',\n",
       " 'of',\n",
       " 'a',\n",
       " 'celebrity',\n",
       " '.',\n",
       " 'A',\n",
       " 'brilliant',\n",
       " 'and',\n",
       " 'successful',\n",
       " 'career',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'open',\n",
       " 'before',\n",
       " 'him',\n",
       " ',',\n",
       " 'but',\n",
       " 'those',\n",
       " 'hope',\n",
       " 'were',\n",
       " 'soon',\n",
       " 'dashed',\n",
       " '.',\n",
       " 'In',\n",
       " '1849',\n",
       " 'he',\n",
       " 'wa',\n",
       " 'arrested',\n",
       " '.',\n",
       " 'Though',\n",
       " 'neither',\n",
       " 'by',\n",
       " 'temperament',\n",
       " 'nor',\n",
       " 'conviction',\n",
       " 'a',\n",
       " 'revolutionist',\n",
       " ',',\n",
       " 'Dostoevsky',\n",
       " 'wa',\n",
       " 'one',\n",
       " 'of',\n",
       " 'a',\n",
       " 'little',\n",
       " 'group',\n",
       " 'of',\n",
       " 'young',\n",
       " 'men',\n",
       " 'who',\n",
       " 'met']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The NLTK  has a lemmatizer that uses the WordNet on-line thesaurus \n",
    "#as a dictionary to look up roots and find the word.\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "crimeLemma = [wnl.lemmatize(t) for t in crimetokens]\n",
    "crimeLemma[:200]\n",
    "\n",
    "#Note that the WordNetLemmatizer does not stem verbs and in general, \n",
    "#doesnât stem very severely at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer: kilometr \n",
      "\n",
      "Lancaster Stemmer: kilomet\n"
     ]
    }
   ],
   "source": [
    "#Lab Assignment\n",
    "#1. First use nltk.word_tokenize() to find the tokens of desert.txt. \n",
    "f = open('desert.txt')\n",
    "deserttext = f.read()\n",
    "\n",
    "deserttokens = nltk.word_tokenize(deserttext)\n",
    "\n",
    "# 2. Use NLTKâs Porter stemmer and Lancaster stemmer to stem the tokens of the desert.txt file. \n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "#compare how the 2 stemmers work on a small portion of the tokens\n",
    "desertPstem = [porter.stem(t) for t in deserttokens]\n",
    "# print(desertPstem[:200],'\\n')\n",
    "desertLstem = [lancaster.stem(t) for t in deserttokens] \n",
    "# print(desertLstem[:200])\n",
    "\n",
    "#3. Choose a number randomly between 0 and 1363 (the length of the tokens is 1364). \n",
    "#I'mma choose 60\n",
    "print(\"Porter Stemmer:\", desertPstem[60],'\\n')\n",
    "print(\"Lancaster Stemmer:\", desertLstem[60])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Post on the course discussion forum the word from desert.txt at that location from both \n",
    "#the Porter and Lancaster stemmed token lists.\n",
    "# Observe whether there was no stemming on that token, the stemming is the same or the\n",
    "# stemming is different between the 2 stemmed lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

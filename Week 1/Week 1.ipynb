{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Class 1\n",
        "**Computational Linguist?**\n",
        "\n",
        "NLP is about both text analysis and text generation \n",
        "\n",
        "## Synchronic model\n",
        "\n\n\n",
        "lexical: word level\n",
        "pragmatic:\n",
        "\n\n",
        "## levels of language)\n",
        "phoeneme\n",
        "morpheme\n",
        "word\n",
        "sentence  \n",
        "text  \n",
        "world  \n",
        "\n",
        "The larger the unit of analysis, that is, the less precise our analysis gets\n",
        "\n\n",
        "- lexical semantics:\n",
        "- laxical category:\n",
        "\n",
        "phonetics rules: deals with pronunciation? Syllables?    \n",
        "phonemic rules: variations of pronounciations when words are spoken together  \n",
        "prosodic rules- fluctuation in a sentence, rhythms, volume tempo etc....  \n",
        "\n\n\n",
        "Morphological analysis: deals with the componential nature of lexical entities: (prefix, stem, suffix and stuff)\n",
        "\n",
        "Lexical level: Part-of-speech tagging tags words with specific noun, verb, adj and adv\n",
        "\n",
        "word level:\n",
        "\n",
        "syntactic level: analyze the words in sentences, grammar: rules that say how words in a language can go together\n",
        "\n",
        "sematic level:\n",
        "\n",
        "discourse: \n",
        "\n",
        "pragmatics:\n",
        "\n\n",
        "### Tokenization (or word segmentation): Decide how to separate the characters in the sentence into individual words.\n",
        "\n",
        "## Terminology for word occurrences:\n",
        "- Tokens: the total number of words\n",
        "- Distinct Tokens (sometimes called word types): number of distinct words, not counting repetitions\n",
        "- e.g. The following sentence from the Brown corpus has 16 tokens\n",
        "and 14 distinct tokens: \"They picnicked by the pool, then lay back on the grass and looked at the stars.\"\n",
        "\n\n\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Word frequencies:\n",
        "1. Count the number of each token aapearing in the corpus\n",
        "2. A frequency distribution\n",
        "3. A word cloud\n",
        "'''\n",
        "\n\n",
        "#Initialing nltk\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import brown\n",
        "import pandas as pd\n",
        "\n",
        "#nltk.download() # to download all the required shit for nltk\n",
        "brown.words()\n",
        "\n",
        "nltk.corpus.gutenberg.fileids()\n",
        "\n",
        "file0 = nltk.corpus.gutenberg.fileids()[0] \n",
        "#file0 = 'austen-emma.txt'\n",
        "\n",
        "#get emma text\n",
        "emmatext=nltk.corpus.gutenberg.raw(file0)\n",
        "\n",
        "#tokenizer in nltk? is token some kind of unique word generator?\n",
        "emmatokens = nltk.word_tokenize(emmatext)\n",
        "\n",
        "#put all the tokens in lower cases\n",
        "emmawords = [w.lower() for w in emmatokens] #list comprehension\n",
        "\n",
        "#put the lower-cased tokens into a set (list without duplicated value)\n",
        "emmavocab = sorted(set(emmawords))\n",
        "\n",
        "#Create a dictionary with words as key and word frequency as values\n",
        "#[('food',3), ('lol',2)]\n",
        "fdist = FreqDist(emmawords)\n",
        "fdistkeys=list(fdist.keys())\n",
        "\n",
        "#print out the most frequent 50 words in the emmawords\n",
        "topkeys=fdist.most_common(50)\n",
        "for pair in topkeys:\n",
        "    print (pair)\n",
        "#DataFrame.from_dict(data, orient='columns', dtype=None)[source]Â¶\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(',', 12016)\n",
            "('.', 6355)\n",
            "('the', 5198)\n",
            "('to', 5179)\n",
            "('and', 4875)\n",
            "('of', 4284)\n",
            "('i', 3164)\n",
            "('a', 3124)\n",
            "('--', 3100)\n",
            "('it', 2500)\n",
            "(\"''\", 2452)\n",
            "('her', 2448)\n",
            "('was', 2396)\n",
            "(';', 2353)\n",
            "('she', 2336)\n",
            "('not', 2279)\n",
            "('in', 2173)\n",
            "('be', 1970)\n",
            "('you', 1962)\n",
            "('he', 1806)\n",
            "('that', 1804)\n",
            "('``', 1735)\n",
            "('had', 1623)\n",
            "('but', 1439)\n",
            "('as', 1436)\n",
            "('for', 1346)\n",
            "('have', 1319)\n",
            "('is', 1241)\n",
            "('with', 1215)\n",
            "('very', 1202)\n",
            "('his', 1140)\n",
            "('mr.', 1089)\n",
            "('!', 1063)\n",
            "('at', 1030)\n",
            "('so', 967)\n",
            "(\"'s\", 866)\n",
            "('emma', 855)\n",
            "('all', 841)\n",
            "('could', 836)\n",
            "('would', 818)\n",
            "('been', 755)\n",
            "('him', 749)\n",
            "('no', 734)\n",
            "('my', 724)\n",
            "('on', 689)\n",
            "('mrs.', 668)\n",
            "('any', 654)\n",
            "('do', 651)\n",
            "('?', 621)\n",
            "('were', 599)\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdist['emma']\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": [
              "855"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you just need an ordered sequence of items? Go for a **list**.  \n",
        "Do you just need to know whether or not you've already got a particular value, but without ordering (and you don't need to store duplicates)? Use a **set**.  \n",
        "Do you need to associate values with keys, so you can look them up efficiently (by key) later on? Use a **dictionary**.  "
      ],
      "metadata": {
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.2.0"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}